{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d60b41",
   "metadata": {},
   "source": [
    "# üìä Data Distribution Analysis\n",
    "## Comprehensive Analysis of 5,000 IMDB Movies Dataset\n",
    "\n",
    "This notebook analyzes the distribution, quality, and characteristics of our movie dataset before model training.\n",
    "\n",
    "**Dataset**: `data/raw/imdb_movies_large.csv`  \n",
    "**Target Variable**: `first_week` (First week box office income)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef1a4e",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (15, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1519c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('data/raw/imdb_movies_large.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "print(f\"Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"\\nDate Range: {df['release_date'].min()} to {df['release_date'].max()}\")\n",
    "print(f\"\\n‚úÖ Dataset loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e45235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e2e4b",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88187bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\" * 80)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing[missing > 0],\n",
    "    'Percentage': missing_pct[missing > 0]\n",
    "})\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    display(missing_df.sort_values('Percentage', ascending=False))\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values found! Dataset is complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364d3381",
   "metadata": {},
   "source": [
    "## 3. Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45c422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24024e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key financial metrics in millions\n",
    "financial_metrics = ['budget', 'revenue', 'first_week', 'opening_weekend', 'total_gross']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FINANCIAL METRICS (in millions $)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in financial_metrics:\n",
    "    if col in df.columns:\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        print(f\"  Mean:   ${df[col].mean()/1e6:>10.2f}M\")\n",
    "        print(f\"  Median: ${df[col].median()/1e6:>10.2f}M\")\n",
    "        print(f\"  Std:    ${df[col].std()/1e6:>10.2f}M\")\n",
    "        print(f\"  Min:    ${df[col].min()/1e6:>10.2f}M\")\n",
    "        print(f\"  Max:    ${df[col].max()/1e6:>10.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056e114d",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4552323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis of target variable (first_week)\n",
    "target = 'first_week'\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TARGET VARIABLE: first_week (First Week Box Office Income)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n{'Statistic':<30} {'Value'}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Count':<30} {df[target].count():>15,}\")\n",
    "print(f\"{'Mean':<30} ${df[target].mean():>14,.2f}\")\n",
    "print(f\"{'Median':<30} ${df[target].median():>14,.2f}\")\n",
    "print(f\"{'Std Dev':<30} ${df[target].std():>14,.2f}\")\n",
    "print(f\"{'Min':<30} ${df[target].min():>14,.2f}\")\n",
    "print(f\"{'25th Percentile':<30} ${df[target].quantile(0.25):>14,.2f}\")\n",
    "print(f\"{'50th Percentile':<30} ${df[target].quantile(0.50):>14,.2f}\")\n",
    "print(f\"{'75th Percentile':<30} ${df[target].quantile(0.75):>14,.2f}\")\n",
    "print(f\"{'90th Percentile':<30} ${df[target].quantile(0.90):>14,.2f}\")\n",
    "print(f\"{'95th Percentile':<30} ${df[target].quantile(0.95):>14,.2f}\")\n",
    "print(f\"{'99th Percentile':<30} ${df[target].quantile(0.99):>14,.2f}\")\n",
    "print(f\"{'Max':<30} ${df[target].max():>14,.2f}\")\n",
    "print(f\"{'Coefficient of Variation':<30} {(df[target].std() / df[target].mean()) * 100:>14.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567cd54",
   "metadata": {},
   "source": [
    "## 5. Distribution Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28942177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of target variable (first_week)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Histogram\n",
    "axes[0, 0].hist(df['first_week'] / 1e6, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Distribution of First Week Income', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('First Week Income (Millions $)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df['first_week'].mean() / 1e6, color='red', linestyle='--', label=f\"Mean: ${df['first_week'].mean()/1e6:.1f}M\")\n",
    "axes[0, 0].axvline(df['first_week'].median() / 1e6, color='green', linestyle='--', label=f\"Median: ${df['first_week'].median()/1e6:.1f}M\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Log-scale histogram\n",
    "axes[0, 1].hist(np.log10(df['first_week'] + 1), bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Distribution of First Week Income (Log Scale)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Log10(First Week Income + 1)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1, 0].boxplot(df['first_week'] / 1e6, vert=True, patch_artist=True,\n",
    "                   boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                   medianprops=dict(color='red', linewidth=2))\n",
    "axes[1, 0].set_title('Box Plot of First Week Income', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('First Week Income (Millions $)')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# QQ plot\n",
    "stats.probplot(df['first_week'], dist=\"norm\", plot=axes[1, 1])\n",
    "axes[1, 1].set_title('Q-Q Plot (Normal Distribution)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print skewness and kurtosis\n",
    "print(f\"\\nSkewness: {stats.skew(df['first_week']):.4f}\")\n",
    "print(f\"Kurtosis: {stats.kurtosis(df['first_week']):.4f}\")\n",
    "print(\"\\n‚ö†Ô∏è Distribution is heavily right-skewed - log transformation recommended!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e450ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of key financial features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# Budget\n",
    "axes[0, 0].hist(df['budget'] / 1e6, bins=50, color='green', edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_title('Budget Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Budget (Millions $)')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].axvline(df['budget'].mean() / 1e6, color='red', linestyle='--', label=f\"Mean: ${df['budget'].mean()/1e6:.1f}M\")\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Revenue\n",
    "axes[0, 1].hist(df['revenue'] / 1e6, bins=50, color='purple', edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Revenue Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Revenue (Millions $)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].axvline(df['revenue'].mean() / 1e6, color='red', linestyle='--', label=f\"Mean: ${df['revenue'].mean()/1e6:.1f}M\")\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# IMDB Rating\n",
    "axes[1, 0].hist(df['imdb_rating'], bins=30, color='orange', edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].set_title('IMDB Rating Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('IMDB Rating')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].axvline(df['imdb_rating'].mean(), color='red', linestyle='--', label=f\"Mean: {df['imdb_rating'].mean():.2f}\")\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# IMDB Votes (log scale)\n",
    "axes[1, 1].hist(np.log10(df['imdb_votes']), bins=40, color='teal', edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].set_title('IMDB Votes Distribution (Log Scale)', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Log10(IMDB Votes)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa7342e",
   "metadata": {},
   "source": [
    "## 6. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4737646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations with target variable\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "target_correlations = df[numerical_cols].corrwith(df['first_week']).sort_values(ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TOP 20 FEATURES CORRELATED WITH FIRST WEEK INCOME\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Feature':<40} {'Correlation':>12}\")\n",
    "print(\"-\" * 80)\n",
    "for feature, corr in target_correlations.head(20).items():\n",
    "    print(f\"{feature:<40} {corr:>12.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BOTTOM 10 FEATURES (Least Correlated)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Feature':<40} {'Correlation':>12}\")\n",
    "print(\"-\" * 80)\n",
    "for feature, corr in target_correlations.tail(10).items():\n",
    "    if pd.notna(corr):\n",
    "        print(f\"{feature:<40} {corr:>12.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175a682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for top features\n",
    "top_features = target_correlations.head(15).index.tolist()\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "correlation_matrix = df[top_features].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap - Top 15 Features', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è WARNING: High correlations detected!\")\n",
    "print(\"Features with >0.95 correlation may indicate data leakage:\")\n",
    "high_corr = correlation_matrix[correlation_matrix > 0.95].stack().reset_index()\n",
    "high_corr = high_corr[high_corr['level_0'] != high_corr['level_1']]\n",
    "if len(high_corr) > 0:\n",
    "    for _, row in high_corr.iterrows():\n",
    "        print(f\"  - {row['level_0']} ‚Üî {row['level_1']}: {row[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27cc29d",
   "metadata": {},
   "source": [
    "## 7. Relationship Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244e34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots: Key features vs First Week\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# Budget vs First Week\n",
    "axes[0, 0].scatter(df['budget'] / 1e6, df['first_week'] / 1e6, alpha=0.5, s=30)\n",
    "axes[0, 0].set_title('Budget vs First Week Income', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Budget (Millions $)')\n",
    "axes[0, 0].set_ylabel('First Week (Millions $)')\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# IMDB Rating vs First Week\n",
    "axes[0, 1].scatter(df['imdb_rating'], df['first_week'] / 1e6, alpha=0.5, s=30, color='green')\n",
    "axes[0, 1].set_title('IMDB Rating vs First Week Income', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('IMDB Rating')\n",
    "axes[0, 1].set_ylabel('First Week (Millions $)')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# IMDB Votes vs First Week (log scale)\n",
    "axes[0, 2].scatter(df['imdb_votes'], df['first_week'] / 1e6, alpha=0.5, s=30, color='purple')\n",
    "axes[0, 2].set_xscale('log')\n",
    "axes[0, 2].set_title('IMDB Votes vs First Week Income', fontsize=12, fontweight='bold')\n",
    "axes[0, 2].set_xlabel('IMDB Votes (log scale)')\n",
    "axes[0, 2].set_ylabel('First Week (Millions $)')\n",
    "axes[0, 2].grid(alpha=0.3)\n",
    "\n",
    "# Popularity vs First Week\n",
    "axes[1, 0].scatter(df['popularity'], df['first_week'] / 1e6, alpha=0.5, s=30, color='orange')\n",
    "axes[1, 0].set_title('Popularity vs First Week Income', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Popularity Score')\n",
    "axes[1, 0].set_ylabel('First Week (Millions $)')\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Twitter Mentions vs First Week\n",
    "axes[1, 1].scatter(df['twitter_mentions'], df['first_week'] / 1e6, alpha=0.5, s=30, color='red')\n",
    "axes[1, 1].set_title('Twitter Mentions vs First Week Income', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Twitter Mentions')\n",
    "axes[1, 1].set_ylabel('First Week (Millions $)')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "# Num Theaters vs First Week\n",
    "axes[1, 2].scatter(df['num_theaters'], df['first_week'] / 1e6, alpha=0.5, s=30, color='teal')\n",
    "axes[1, 2].set_title('Number of Theaters vs First Week Income', fontsize=12, fontweight='bold')\n",
    "axes[1, 2].set_xlabel('Number of Theaters')\n",
    "axes[1, 2].set_ylabel('First Week (Millions $)')\n",
    "axes[1, 2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70d6b4e",
   "metadata": {},
   "source": [
    "## 8. Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebda9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from release_date\n",
    "df['year'] = pd.to_datetime(df['release_date']).dt.year\n",
    "\n",
    "# Movies per year\n",
    "year_counts = df['year'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "plt.bar(year_counts.index, year_counts.values, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "plt.title('Number of Movies per Year (1990-2024)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Number of Movies', fontsize=12)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal years covered: {year_counts.index.min()} - {year_counts.index.max()}\")\n",
    "print(f\"Average movies per year: {year_counts.mean():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7d8abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top genres\n",
    "genre_counts = df['genre'].value_counts().head(15)\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.barh(range(len(genre_counts)), genre_counts.values, color='coral', edgecolor='black', alpha=0.7)\n",
    "plt.yticks(range(len(genre_counts)), genre_counts.index)\n",
    "plt.title('Top 15 Most Common Genres', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Number of Movies', fontsize=12)\n",
    "plt.ylabel('Genre', fontsize=12)\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal unique genres: {df['genre'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c86a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequels vs Original movies\n",
    "if 'is_sequel' in df.columns:\n",
    "    sequel_data = df.groupby('is_sequel')['first_week'].agg(['mean', 'median', 'count'])\n",
    "    sequel_data.index = ['Original', 'Sequel']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Count\n",
    "    axes[0].bar(sequel_data.index, sequel_data['count'], color=['steelblue', 'coral'], \n",
    "                edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title('Original vs Sequel Movies', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Number of Movies')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(sequel_data['count']):\n",
    "        axes[0].text(i, v + 50, str(int(v)), ha='center', fontweight='bold')\n",
    "    \n",
    "    # Average First Week Income\n",
    "    axes[1].bar(sequel_data.index, sequel_data['mean'] / 1e6, color=['steelblue', 'coral'],\n",
    "                edgecolor='black', alpha=0.7)\n",
    "    axes[1].set_title('Average First Week Income', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel('First Week Income (Millions $)')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(sequel_data['mean'] / 1e6):\n",
    "        axes[1].text(i, v + 2, f'${v:.1f}M', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSequels earn {sequel_data.loc['Sequel', 'mean'] / sequel_data.loc['Original', 'mean']:.2f}x more on average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3228c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summer vs Non-summer releases\n",
    "if 'is_summer' in df.columns:\n",
    "    summer_data = df.groupby('is_summer')['first_week'].agg(['mean', 'median', 'count'])\n",
    "    summer_data.index = ['Non-Summer', 'Summer']\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Count\n",
    "    axes[0].bar(summer_data.index, summer_data['count'], color=['lightblue', 'orange'],\n",
    "                edgecolor='black', alpha=0.7)\n",
    "    axes[0].set_title('Summer vs Non-Summer Releases', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Number of Movies')\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    for i, v in enumerate(summer_data['count']):\n",
    "        axes[0].text(i, v + 50, str(int(v)), ha='center', fontweight='bold')\n",
    "    \n",
    "    # Average First Week Income\n",
    "    if summer_data['count'].min() > 0:  # Only if we have both categories\n",
    "        axes[1].bar(summer_data.index, summer_data['mean'] / 1e6, color=['lightblue', 'orange'],\n",
    "                    edgecolor='black', alpha=0.7)\n",
    "        axes[1].set_title('Average First Week Income', fontsize=14, fontweight='bold')\n",
    "        axes[1].set_ylabel('First Week Income (Millions $)')\n",
    "        axes[1].grid(axis='y', alpha=0.3)\n",
    "        for i, v in enumerate(summer_data['mean'] / 1e6):\n",
    "            axes[1].text(i, v + 2, f'${v:.1f}M', ha='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366984d9",
   "metadata": {},
   "source": [
    "## 9. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eda7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier detection using IQR method\n",
    "outlier_features = ['budget', 'revenue', 'first_week', 'opening_weekend', 'imdb_votes']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"OUTLIER DETECTION (IQR Method)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Feature':<25} {'Outliers':>10} {'Percentage':>12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "outlier_summary = {}\n",
    "for col in outlier_features:\n",
    "    if col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()\n",
    "        pct = (outliers / len(df)) * 100\n",
    "        outlier_summary[col] = {'count': outliers, 'percentage': pct}\n",
    "        print(f\"{col:<25} {outliers:>10} {pct:>11.2f}%\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è Note: High outlier percentages indicate skewed distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27685b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "for idx, col in enumerate(outlier_features):\n",
    "    if col in df.columns:\n",
    "        row = idx // 3\n",
    "        col_idx = idx % 3\n",
    "        \n",
    "        axes[row, col_idx].boxplot(df[col] / 1e6 if col != 'imdb_votes' else df[col],\n",
    "                                   vert=True, patch_artist=True,\n",
    "                                   boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                                   medianprops=dict(color='red', linewidth=2),\n",
    "                                   flierprops=dict(marker='o', markerfacecolor='red', markersize=4, alpha=0.5))\n",
    "        \n",
    "        title = col.replace('_', ' ').title()\n",
    "        axes[row, col_idx].set_title(f'Box Plot: {title}', fontsize=12, fontweight='bold')\n",
    "        ylabel = f\"{title} ({'Millions $' if col != 'imdb_votes' else 'Votes'})\"\n",
    "        axes[row, col_idx].set_ylabel(ylabel)\n",
    "        axes[row, col_idx].grid(alpha=0.3)\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[1, 2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb56d54",
   "metadata": {},
   "source": [
    "## 10. Distribution Shapes (Skewness & Kurtosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate skewness and kurtosis\n",
    "key_features = ['budget', 'revenue', 'first_week', 'imdb_rating', 'imdb_votes']\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DISTRIBUTION ANALYSIS - SKEWNESS AND KURTOSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\n{'Feature':<25} {'Skewness':>12} {'Kurtosis':>12} {'Distribution'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for col in key_features:\n",
    "    if col in df.columns and df[col].std() > 0:\n",
    "        skew = stats.skew(df[col].dropna())\n",
    "        kurt = stats.kurtosis(df[col].dropna())\n",
    "        \n",
    "        # Interpret distribution\n",
    "        if abs(skew) < 0.5:\n",
    "            dist = \"‚úÖ Normal\"\n",
    "        elif skew > 1:\n",
    "            dist = \"‚ö†Ô∏è Highly Right-skewed\"\n",
    "        elif skew > 0:\n",
    "            dist = \"‚ö†Ô∏è Right-skewed\"\n",
    "        elif skew < -1:\n",
    "            dist = \"‚ö†Ô∏è Highly Left-skewed\"\n",
    "        else:\n",
    "            dist = \"‚ö†Ô∏è Left-skewed\"\n",
    "        \n",
    "        print(f\"{col:<25} {skew:>12.4f} {kurt:>12.4f} {dist}\")\n",
    "\n",
    "print(\"\\nüí° Interpretation:\")\n",
    "print(\"  ‚Ä¢ Skewness close to 0: Normal distribution\")\n",
    "print(\"  ‚Ä¢ Skewness > 1: Highly right-skewed (log transformation recommended)\")\n",
    "print(\"  ‚Ä¢ Kurtosis > 3: Heavy tails (more outliers than normal distribution)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484bb63d",
   "metadata": {},
   "source": [
    "## 11. Data Quality Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0433215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA QUALITY RECOMMENDATIONS FOR MODEL TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "recommendations = []\n",
    "\n",
    "# Check skewness\n",
    "for col in ['budget', 'revenue', 'first_week', 'imdb_votes']:\n",
    "    if col in df.columns:\n",
    "        skew = stats.skew(df[col].dropna())\n",
    "        if abs(skew) > 1:\n",
    "            recommendations.append(f\"‚ö†Ô∏è  '{col}' is highly skewed ({skew:.2f}). Apply log transformation: log(x + 1)\")\n",
    "\n",
    "# Check outliers\n",
    "for col in outlier_features:\n",
    "    if col in df.columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        outliers = ((df[col] < (Q1 - 1.5 * IQR)) | (df[col] > (Q3 + 1.5 * IQR))).sum()\n",
    "        pct = (outliers / len(df)) * 100\n",
    "        if pct > 5:\n",
    "            recommendations.append(f\"‚ö†Ô∏è  '{col}' has {pct:.1f}% outliers. Consider RobustScaler or keep for ensemble models.\")\n",
    "\n",
    "# Check scale differences\n",
    "recommendations.append(\"‚ö†Ô∏è  Features have vastly different scales (1-5B). Use StandardScaler or RobustScaler.\")\n",
    "\n",
    "# Check correlation (data leakage)\n",
    "high_corr_features = target_correlations[target_correlations > 0.95].index.tolist()\n",
    "if len(high_corr_features) > 2:\n",
    "    leakage_features = [f for f in high_corr_features if f not in ['first_week']]\n",
    "    recommendations.append(f\"üö® DATA LEAKAGE: Remove these features: {', '.join(leakage_features)}\")\n",
    "\n",
    "# Print recommendations\n",
    "print(\"\\nüìã Action Items:\\n\")\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECOMMENDED FEATURE ENGINEERING STEPS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. Remove Data Leakage:\n",
    "   ‚úó Drop: opening_weekend, average_per_theater, total_gross, revenue\n",
    "   ‚úì Keep: budget, ratings, social media, temporal features\n",
    "\n",
    "2. Apply Log Transformations:\n",
    "   ‚Ä¢ log(budget + 1)\n",
    "   ‚Ä¢ log(first_week + 1)  [TARGET]\n",
    "   ‚Ä¢ log(imdb_votes + 1)\n",
    "   ‚Ä¢ log(ticket_presales + 1)\n",
    "\n",
    "3. Feature Scaling:\n",
    "   ‚Ä¢ Use RobustScaler (handles outliers better)\n",
    "   ‚Ä¢ Or StandardScaler for tree-based models\n",
    "\n",
    "4. Handle Outliers:\n",
    "   ‚Ä¢ Keep outliers (blockbusters are real data!)\n",
    "   ‚Ä¢ Use robust models: Random Forest, XGBoost, CatBoost\n",
    "\n",
    "5. Feature Selection:\n",
    "   ‚Ä¢ Focus on features with correlation > 0.3\n",
    "   ‚Ä¢ Consider feature importance from tree models\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd1151",
   "metadata": {},
   "source": [
    "## 12. Key Insights Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"KEY INSIGHTS FROM DATA ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# ROI\n",
    "roi = (df['revenue'] / df['budget']).median()\n",
    "insights.append(f\"üí∞ Median ROI: {roi:.2f}x (most movies don't break even!)\")\n",
    "\n",
    "# Rating\n",
    "high_rated = (df['imdb_rating'] >= 8.0).sum()\n",
    "insights.append(f\"‚≠ê {high_rated} movies ({high_rated/len(df)*100:.1f}%) rated 8.0+\")\n",
    "\n",
    "# Popularity\n",
    "popular = (df['imdb_votes'] >= 500000).sum()\n",
    "insights.append(f\"üé¨ {popular} blockbusters ({popular/len(df)*100:.1f}%) have 500K+ votes\")\n",
    "\n",
    "# Sequels\n",
    "if 'is_sequel' in df.columns and df['is_sequel'].sum() > 0:\n",
    "    sequel_avg = df[df['is_sequel'] == 1]['first_week'].mean()\n",
    "    original_avg = df[df['is_sequel'] == 0]['first_week'].mean()\n",
    "    ratio = sequel_avg / original_avg\n",
    "    insights.append(f\"üé≠ Sequels earn {ratio:.2f}x {'more' if ratio > 1 else 'less'} in first week\")\n",
    "\n",
    "# Budget correlation\n",
    "budget_corr = df['budget'].corr(df['first_week'])\n",
    "insights.append(f\"üíµ Budget correlation with first week: {budget_corr:.3f} (strong positive)\")\n",
    "\n",
    "# Social media impact\n",
    "twitter_corr = df['twitter_mentions'].corr(df['first_week'])\n",
    "insights.append(f\"üì± Twitter mentions correlation: {twitter_corr:.3f} (moderate positive)\")\n",
    "\n",
    "# Target variance\n",
    "cv = (df['first_week'].std() / df['first_week'].mean()) * 100\n",
    "insights.append(f\"üìä First week income has {cv:.1f}% coefficient of variation (highly variable!)\")\n",
    "\n",
    "# Print insights\n",
    "print(\"\\nüîç Insights:\\n\")\n",
    "for insight in insights:\n",
    "    print(f\"  {insight}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ ANALYSIS COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset: data/raw/imdb_movies_large.csv\")\n",
    "print(f\"Movies: {len(df):,}\")\n",
    "print(f\"Features: {len(df.columns)}\")\n",
    "print(f\"Target: first_week (${df['first_week'].mean():,.0f} average)\")\n",
    "print(f\"\\nüí° Data is ready for feature engineering and model training!\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d07da49",
   "metadata": {},
   "source": [
    "## 13. Next Steps\n",
    "\n",
    "### Recommended Actions:\n",
    "\n",
    "1. **Feature Engineering**:\n",
    "   - Remove data leakage features (opening_weekend, average_per_theater, total_gross, revenue)\n",
    "   - Apply log transformations to skewed features\n",
    "   - Scale features using RobustScaler\n",
    "\n",
    "2. **Model Training**:\n",
    "   - Use ensemble methods (Random Forest, XGBoost, CatBoost)\n",
    "   - Implement stacking with meta-learner\n",
    "   - Cross-validation for robust evaluation\n",
    "\n",
    "3. **Model Evaluation**:\n",
    "   - RMSE, MAE, R¬≤ metrics\n",
    "   - Feature importance analysis\n",
    "   - Residual analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to proceed with model training! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
